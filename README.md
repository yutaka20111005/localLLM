# localLLM

１．動作環境  
　　Ubuntu Desktop 22.04 VM on VMWare workstation  
　　python 3.10  
  llama-cpp-python　＜＝＝ pip install  
  tinyllama-1.1b-chat-v1.0.Q8_0.gguf　＜＝＝Hugging FaceよりDownloadしたローカルLLM用。  


  ２．実行  
  　　python localLLM_chat.py  
    
  ３．表示例  
  　　![image](https://github.com/user-attachments/assets/934698c2-1171-4be3-a7d9-38e062a908c6)  

　４．課題  
 　　　日本語の質問への対応能力アップw、及び質問文章のレベルアップも含め。

    　※主観レベルで変な動作をしたように思えたことが1度あったので、セキュリティ面では注意したい。
     　　モデルに対するウイルススキャン等でどこまで対応可能か・・。
  
