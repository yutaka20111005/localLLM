# localLLM

１．動作環境  
　　Ubuntu Desktop 22.04 VM on VMWare workstation  
  　python 3.10  
    llama-cpp-python　＜＝＝ pip install
    tinyllama-1.1b-chat-v1.0.Q8_0.gguf　＜＝＝Hugging FaceよりDownloadしたローカルLLM用。  


  ２．実行  
  　　python localLLM_chat.py  
    
  ３．表示例  
  　　![image](https://github.com/user-attachments/assets/934698c2-1171-4be3-a7d9-38e062a908c6)  

  
