# localLLM

１．動作環境  
　　Ubuntu Desktop 22.04 VM on VMWare workstation  
　　python 3.10  
　　llama-cpp-python　＜＝＝ pip install  
　　tinyllama-1.1b-chat-v1.0.Q8_0.gguf　＜＝＝Hugging FaceよりDownloadしたローカルLLM用。  


  ２．実行  
  　　python localLLM_chat.py  
    
  ３．表示例 （色をつけました）  
  　　![image](https://github.com/user-attachments/assets/29c7a37c-c8dd-45b3-a711-242f21e0f368)
 

　４．課題  
 　　　日本語の質問への対応能力アップw、及び質問文章のレベルアップも含め。

    　※主観レベルで変な動作をしたように思えたことが1度あったので、セキュリティ面では注意したい。
     　　モデルに対するウイルススキャン等でどこまで対応可能か・・。
  
